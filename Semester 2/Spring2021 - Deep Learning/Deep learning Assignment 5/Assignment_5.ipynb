{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J7bAi_HECRx"
      },
      "source": [
        "### Data Preprocessing \n",
        "You can use your own way of preprocessing to enhance results. Best results will lead to bonus points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTAPLzutECR0"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "import re\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from keras import models    \n",
        "from tensorflow.keras.models import load_model   # load saved model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N2uVO66ECR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc57194-f104-42bf-8eb7-3c1a376051b9"
      },
      "source": [
        "reviews = pd.read_csv(\"imdb_dataset.csv\")\n",
        "\n",
        "print(reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "47995  First of all, Blythe Danner doesn't look anywh...  negative\n",
            "47996  I wouldn't be so quick to look at all the good...  negative\n",
            "47997  Everything about this show is terrible. Its pr...  negative\n",
            "47998  This movie just was not very funny. There's no...  negative\n",
            "47999  \"The Yoke's on Me\" is undoubtedly the most con...  negative\n",
            "\n",
            "[48000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JTilXMapn7"
      },
      "source": [
        "\n",
        "english_stops = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXTIESMrECR3"
      },
      "source": [
        "def preprocess(text):\n",
        "    lower = text.lower()\n",
        "    # Removing Punctuation marks\n",
        "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "    rem_punc = tokenizer.tokenize(lower)\n",
        "    # Removing Stop Words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    rem_stop_words = [word for word in rem_punc if not word in stopwords]\n",
        "    # Removing Non-English words \n",
        "    english_words = nltk.corpus.words.words()\n",
        "    english_words = [word for word in rem_stop_words if word in english_words]   \n",
        "    # Insert Start End tokens\n",
        "    english_words.insert(0,'<start>')\n",
        "    english_words.append('<end>')\n",
        "    sentence = ' '.join(english_words)\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kje6bbrDECR3"
      },
      "source": [
        "def encode_text(text):\n",
        "    # Tokenization\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    # Converting to sequences\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    # Padding Zeros \n",
        "    tokenizer.word_index['<pad>'] = 0\n",
        "    tokenizer.index_word[0] = '<pad>'\n",
        "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "    \n",
        "    return padded_sequences, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py_jYiVKZMXr",
        "outputId": "70ad53b8-a150-48bd-b1e1-69d3133049db"
      },
      "source": [
        "nltk.download(\"stopwords\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQTtE8rRe3vx",
        "outputId": "e1db82a3-7fa0-487e-fe7e-46184404031f"
      },
      "source": [
        "nltk.download(\"words\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-JiWypAECR4"
      },
      "source": [
        "text = list(map(preprocess,reviews.review[:10]))\n",
        "encodings, tokenizer = encode_text(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVRb7a2yLPR2",
        "outputId": "6b62ecf2-d7b9-440d-c171-1c6c9c71f0af"
      },
      "source": [
        "def load_dataset():\n",
        "    df = pd.read_csv('imdb_dataset.csv')\n",
        "    x_data = df['review']       # Reviews/Input\n",
        "    y_data = df['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "   # x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "    \n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reviews\n",
            "0        [o, n, e,  , o, f,  , t, h, e,  , o, t, h, e, ...\n",
            "1        [a,  , w, o, n, d, e, r, f, u, l,  , l, i, t, ...\n",
            "2        [i,  , t, h, o, u, g, h, t,  , t, h, i, s,  , ...\n",
            "3        [b, a, s, i, c, a, l, l, y,  , t, h, e, r, e, ...\n",
            "4        [p, e, t, t, e, r,  , m, a, t, t, e, i,  , s, ...\n",
            "                               ...                        \n",
            "47995    [f, i, r, s, t,  , o, f,  , a, l, l,  ,  , b, ...\n",
            "47996    [i,  , w, o, u, l, d, n,  , t,  , b, e,  , s, ...\n",
            "47997    [e, v, e, r, y, t, h, i, n, g,  , a, b, o, u, ...\n",
            "47998    [t, h, i, s,  , m, o, v, i, e,  , j, u, s, t, ...\n",
            "47999    [ , t, h, e,  , y, o, k, e,  , s,  , o, n,  , ...\n",
            "Name: review, Length: 48000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "47995    0\n",
            "47996    0\n",
            "47997    0\n",
            "47998    0\n",
            "47999    0\n",
            "Name: sentiment, Length: 48000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l7GsOoUECR4"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWMSGSfbLPR3",
        "outputId": "4272566d-c3cb-43cf-ecf0-11bfa9d1fbbb"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set\n",
            "30758    [i, n,  , t, h, e,  , i, m, m, o, r, t, a, l, ...\n",
            "7206     [t, h, e,  , w, o, r, d,  , h, o, n, o, r,  , ...\n",
            "25777    [ , w, i, t, h,  , a, l, l,  , t, h, e,  , m, ...\n",
            "36185    [t, h, e, r, e,  , s,  , n, o, t, h, i, n, g, ...\n",
            "13321    [i,  , v, e,  , b, e, e, n,  , a, b, l, e,  , ...\n",
            "                               ...                        \n",
            "46693    [t, h, i, s,  , i, s,  , t, h, e,  , o, n, l, ...\n",
            "45234    [t, y, r, a,  , b, a, n, k, s,  , n, e, e, d, ...\n",
            "32380    [o, k,  ,  , i, t,  , w, a, s,  , a,  , g, o, ...\n",
            "2856     [i,  , r, e, n, t, e, d,  , t, h, i, s,  , m, ...\n",
            "6802     [i, f,  , w, e,  , r, e, a, l, l, y,  , w, a, ...\n",
            "Name: review, Length: 38400, dtype: object \n",
            "\n",
            "42093    [h, u, g, e,  ,  , e, x, h, a, u, s, t, i, v, ...\n",
            "40077    [d, e, s, p, i, t, e,  , u, n, f, o, r, t, u, ...\n",
            "44348    [l, e, t,  , m, e,  , s, a, y,  , t, h, a, t, ...\n",
            "31798    [t, h, e, r, e,  , i, s,  , a,  , v, e, r, s, ...\n",
            "47518    [w, e,  , f, o, u, n, d,  , t, h, i, s,  , m, ...\n",
            "                               ...                        \n",
            "28921    [i,  , m,  , n, o, t,  , s, u, r, e,  , w, h, ...\n",
            "23594    [i,  , c, o, n, s, i, d, e, r,  , t, h, i, s, ...\n",
            "32517    [i,  , d, i, d,  , n, o, t,  , k, n, o, w,  , ...\n",
            "10984    [i,  , t, h, i, n, k,  , i,  , s, h, o, u, l, ...\n",
            "4732     [m, y,  , w, i, f, e,  , i, s,  , a,  , m, e, ...\n",
            "Name: review, Length: 9600, dtype: object \n",
            "\n",
            "Test Set\n",
            "30758    1\n",
            "7206     0\n",
            "25777    1\n",
            "36185    0\n",
            "13321    1\n",
            "        ..\n",
            "46693    0\n",
            "45234    0\n",
            "32380    1\n",
            "2856     0\n",
            "6802     0\n",
            "Name: sentiment, Length: 38400, dtype: int64 \n",
            "\n",
            "42093    1\n",
            "40077    0\n",
            "44348    1\n",
            "31798    1\n",
            "47518    0\n",
            "        ..\n",
            "28921    0\n",
            "23594    1\n",
            "32517    1\n",
            "10984    0\n",
            "4732     1\n",
            "Name: sentiment, Length: 9600, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5W7y3bNLPR3"
      },
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1w3vxL0Wfdy",
        "outputId": "4e3a27b1-8d51-441a-b1b5-ae7dc68e322c"
      },
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[ 5  8  1 ...  5 17 10]\n",
            " [ 3 10  2 ...  8 12  7]\n",
            " [ 1 19  5 ...  2  1  2]\n",
            " ...\n",
            " [ 6 23  1 ...  0  0  0]\n",
            " [ 5  1  9 ...  0  0  0]\n",
            " [ 5 16  1 ...  0  0  0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[10 15 17 ...  0  0  0]\n",
            " [12  2  7 ...  0  0  0]\n",
            " [11  2  3 ...  0  0  0]\n",
            " ...\n",
            " [ 5  1 12 ...  1 19  2]\n",
            " [ 5  1  3 ... 13 23  1]\n",
            " [14 18  1 ...  0  0  0]] \n",
            "\n",
            "Maximum review length:  1287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecA-GE1nWp6g",
        "outputId": "20a189d9-7e3b-4e91-ddab-6ffb2d854d9b"
      },
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1287, 32)          896       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 25,793\n",
            "Trainable params: 25,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5yjIWyVX09X"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVtdxYe-crVl",
        "outputId": "142a1b86-d222-4f52-939c-e19424d0872f"
      },
      "source": [
        "\n",
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 365s 1s/step - loss: 0.6932 - accuracy: 0.5022\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.50216, saving model to models/LSTM.h5\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 363s 1s/step - loss: 0.6930 - accuracy: 0.5053\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.50216 to 0.50534, saving model to models/LSTM.h5\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 372s 1s/step - loss: 0.6935 - accuracy: 0.5045\n",
            "\n",
            "Epoch 00003: accuracy did not improve from 0.50534\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 371s 1s/step - loss: 0.6927 - accuracy: 0.5092\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.50534 to 0.50922, saving model to models/LSTM.h5\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 370s 1s/step - loss: 0.6938 - accuracy: 0.5053\n",
            "\n",
            "Epoch 00005: accuracy did not improve from 0.50922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f75eaab89d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XncaqweXcz9r"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMolftuvcwiG",
        "outputId": "c5311caa-8d37-4f5c-9528-175d333075d4"
      },
      "source": [
        "\n",
        "y_pred = model.predict_classes(x_test, batch_size = 128)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Correct Prediction: 4807\n",
            "Wrong Prediction: 4793\n",
            "Accuracy: 50.072916666666664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjHUl1m9llGv"
      },
      "source": [
        "loaded_model = load_model('models/LSTM.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUo99KLkYIlj",
        "outputId": "ec80b18b-b00a-404d-e263-baff81fadf51"
      },
      "source": [
        "review = str(input('Movie Review: '))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie Review:  Nothing was typical about this. Everything was beautifully done in this movie, the story, the flow, the scenario, everything. I highly recommend it for mystery lovers, for anyone who wants to watch a good movie!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y8OgeOqZIfd",
        "outputId": "a0828496-7238-4b55-9adc-6076117d0bb3"
      },
      "source": [
        "\n",
        "# Pre-process input\n",
        "regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "review = regex.sub('', review)\n",
        "print('Cleaned: ', review)\n",
        "\n",
        "words = review.split(' ')\n",
        "filtered = [w for w in words if w not in english_stops]\n",
        "filtered = ' '.join(filtered)\n",
        "filtered = [filtered.lower()]\n",
        "\n",
        "print('Filtered: ', filtered)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaned:   Nothing was typical about this Everything was beautifully done in this movie the story the flow the scenario everything I highly recommend it for mystery lovers for anyone who wants to watch a good movie\n",
            "Filtered:  [' nothing typical everything beautifully done movie story flow scenario everything i highly recommend mystery lovers anyone wants watch good movie']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt7cdORUZNg4",
        "outputId": "0f851883-0d5e-44b9-cb88-dafdf7ab1c2d"
      },
      "source": [
        "tokenize_words = token.texts_to_sequences(filtered)\n",
        "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "print(tokenize_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us4S9UPCZbNO",
        "outputId": "2bfd3d7a-7aad-431c-c162-dcc77eb21c60"
      },
      "source": [
        "result = loaded_model.predict(tokenize_words)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.488618]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0uAID8tZc85",
        "outputId": "f42e7115-264c-41a8-e448-f093cc605e7e"
      },
      "source": [
        "if result >= 0.7:\n",
        "    print('positive')\n",
        "else:\n",
        "    print('negative')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPieHe7PmE6D"
      },
      "source": [
        "#Plot The Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PUcTL37nDpw",
        "outputId": "290b7048-f7f3-4246-b1a0-45a6e1ed4ed4"
      },
      "source": [
        "test_metrics = model.evaluate(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200/1200 [==============================] - 158s 131ms/step - loss: 0.6927 - accuracy: 0.5088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6UTtxEGnJFH",
        "outputId": "3fe3a113-4c37-4381-9e98-963dc7b1688e"
      },
      "source": [
        "\n",
        "test_accuracy = test_metrics[1] \n",
        "test_loss = test_metrics[0]\n",
        "print(\"Test Accuracy :\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.5088281035423279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "gIaLl5e9mEAy",
        "outputId": "52ba4a62-e1dc-4c7e-bfb3-5380d014438c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_train = checkpoint.checkpoint['accu']\n",
        "x_train = checkpoint.checkpoint['val_accu']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "plt.plot(epochs, y_train, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-b37e1fdca7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ModelCheckpoint' object has no attribute 'checkpoint'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhC27eiZmsJr"
      },
      "source": [
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, train_loss, 'bo', label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training & Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}