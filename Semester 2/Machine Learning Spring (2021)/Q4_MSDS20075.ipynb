{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q4_MSDS20075.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD-lBdBqKHzE"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiteWUf1g_xK"
      },
      "source": [
        "# **3    Question 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HotLBNi6hRX8"
      },
      "source": [
        "import numpy as np \n",
        "np.random.seed(2017)\n",
        "n = 100\n",
        "trainX = np.random.rand(n)\n",
        "trainY = np.sin(9*trainX) + np.sqrt(1/3.0)*np.random.randn(n)\n",
        "testX=np.linspace(0,1001)\n",
        "testY = np.sin(9*testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDskCX-q3ujY"
      },
      "source": [
        "**3.0.1 part(A)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0wYRMUMi57r"
      },
      "source": [
        "gamma = 0.2\n",
        "lmbda = 0.07\n",
        "K_tr = np.empty ((len(trainX), len(trainX) ))\n",
        "for i in range(len(trainX)):\n",
        "    K_tr[i,:] = np.exp(-gamma*np.abs(trainX -trainX[i]))\n",
        "\n",
        "K_test = np.empty((len(testX),len(trainX)))\n",
        "for i in range(len(testX)):\n",
        "    K_test[i,:] = np.exp(-gamma*np.abs(trainX - testX[i] ))\n",
        "\n",
        "inv_K = np.linalg.inv(K_tr + lmbda*np.identity((len(trainX)))) \n",
        "\n",
        "# final equation \n",
        "#  *These results hve been generated on hit and trail basis*  \n",
        "#  Best gamma = 0.2 \n",
        "#  Best Lambda = 0.07\n",
        "#  Training Error = 0.0356\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJZyvP_QnBAl"
      },
      "source": [
        "**3.0.2 Part(B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd59r4SynHcT"
      },
      "source": [
        "best_eps = 0\n",
        "best_g = 0\n",
        "best_c = 0\n",
        "err_tr = 1000\n",
        "err_test = 1000\n",
        "\n",
        "for eps in np.linspace(0.001, 1, 20):\n",
        "    reg = SVR(C=1.0, epsilon=eps, kernel='rbf',gamma=1.0)\n",
        "    reg.fit(trainX[:,None],trainY)\n",
        "    mse_tr = mse(trainY, y_pred=reg.predict(trainX[:,None]), got_pred=True)\n",
        "    if mse_tr < err_tr:\n",
        "        best_eps = eps\n",
        "for g in np.linspace(1, 2, 20):\n",
        "    reg = SVR(C=1.0, epsilon=best_eps, kernsl='rbf', gamma=g)\n",
        "    mse_tr = mse(trainY, predictions=reg.predictt(trainx[:,None]), got_pred=True)\n",
        "    if mse_tr < err-tr:\n",
        "        best_g = g\n",
        "\n",
        "\n",
        "for c in np.linspace(1, 200, 20) :  \n",
        "    reg = SVR(C=c, eplison=best_eps, kernel='rbf', gamma=best_g)\n",
        "    reg.fit(trainX[:,None],trainY)\n",
        "    mse_tr = mse(trainY, predictions=reg.predict(trainC[:,none]), got_pred=True)\n",
        "    if mse_tr < err_tr:\n",
        "        err_tr = mse_tr\n",
        "        err_test = mse(testY, predictions=reg.predict(testX[:,None]),got_pred=True)\n",
        "        best_c = c\n",
        "        \n",
        "print(\"Best eplison = {:.2f}\\nBest gamma =   {:.2f}\\nBest C = {:.2f}\".format(best_eps,best_g,best_C))\n",
        "print(\"Training Error = {:.4f}\\nTesting Error = {:.4f}\".format(err_tr,err_test))\n",
        "\n",
        "reg = SVR(C=best_c, epsilon=best_eps, kernel='rbf', gamma=best_g)\n",
        "reg.fit(trainX[:,None],trainY)\n",
        "# Best eplison = 1.00\n",
        "# Best gamma = 2.00\n",
        "# Best C = 189.53\n",
        "# Training Error = 0.3461\n",
        "# Testing Error = 0.0778"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDCIOLLzu4ff"
      },
      "source": [
        "**3.0.3  Part(C)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "63cdto6SvA-g",
        "outputId": "f0a1f415-f6ec-4d53-c3c9-fc633aed9df8"
      },
      "source": [
        "'''Both the method tend to learn good non-linear curve for training Data. However my experimenta-\n",
        "tion proved that results for method used in part A are better and it fits training data quite\n",
        "better but the non-linearity seems to be increased in it as compared to method in partB. About\n",
        "bandwidth, it makes model in method 0f partA more non-linear than the other.'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Both the method tend to learn good non-linear curve for training Data. However my experimenta-\\ntion proved that results for method used in part A are better and it fits training data quite\\nbetter but the non-linearity seems to be increased in it as compared to method in partB. About\\nbandwidth, it makes model in method 0f partA more non-linear than the other.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    }
  ]
}